\chapter{Estimation}
\label{chap:estimation}

\Opensolutionfile{reponses}[reponses-estimation]
\Opensolutionfile{solutions}[solutions-estimation]

\begin{Filesave}{reponses}
\bigskip
\section*{Réponses}

\end{Filesave}

\begin{Filesave}{solutions}
\section*{Chapitre \ref{chap:estimation}}
\addcontentsline{toc}{section}{Chapitre \protect\ref{chap:estimation}}

\end{Filesave}


<<echo=FALSE>>=
options(width = 52)
@


\begin{exercice}
  On vous donne les valeurs suivantes provenant d'un processus
  autorégressif d'ordre 1:
<<echo=FALSE>>=
set.seed(12345)
ar1 <- round(tail(arima.sim(list(ar = 0.85), n = 100, sd = 4), 8), 1)
@
  \begin{displaymath}
    \Sexpr{format(ar1[1], dec = ",")} \quad
    \Sexpr{format(ar1[2], dec = ",")} \quad
    \Sexpr{format(ar1[3], dec = ",")} \quad
    \Sexpr{format(ar1[4], dec = ",")} \quad
    \Sexpr{format(ar1[5], dec = ",")} \quad
    \Sexpr{format(ar1[6], dec = ",")} \quad
    \Sexpr{format(ar1[7], dec = ",")} \quad
    \Sexpr{format(ar1[8], dec = ",")}.
  \end{displaymath}
  \begin{enumerate}
  \item Estimer la valeur de $\phi_{11}$ à partir des données
    ci-dessus.
  \item Si on vous dit que $\phi = 0,85$, que vaut $\phi_{22}$ (la
    valeur théorique)? Justifier votre réponse.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
    \item $-0,2695$
    \item $0$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item La première autocorrélation partielle est toujours égale à
      la première autocorrélation. Par conséquent,
      \begin{align*}
        \hat{\phi}_{11}
        &= \hat{\rho}(1) \\
        &= \frac{\sum_{t=1}^{n-1} (x_t - \bar{x})(x_{t+1} -
          \bar{x})}{\sum_{t=1}^n (x_t - \bar{x})^2} \\
        &= -0,2695.
      \end{align*}
    \item Pour un processus AR(1), on a toujours $\phi_{22} = 0$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  Trouver les estimateurs de Yule--Walker des paramètres $\theta$ et
  $\sigma^2$ du modèle MA(1) en supposant que $|\rho(1)| <
  \frac{1}{2}$.
  \begin{rep}
    $\hat{\theta} = (1 - \sqrt{1 - 4 \hat{\rho}(1)^2})/(2
    \hat{\rho}(1))$
  \end{rep}
  \begin{sol}
    On sait des notes de cours que les estimateurs de Yule--Walker des
    paramètres $\theta$ et $\sigma^2$ d'un modèle MA$(1)$ sont obtenus
    avec
    \begin{align*}
      \hat{\sigma}^2 &= \frac{\hat{\gamma}(1)}{\hat{\theta}} \\
      \hat{\rho}(1) &= \frac{\hat{\theta}}{1 + \hat{\theta}^2}.
    \end{align*}
    En isolant $\hat{\theta}$ dans la seconde équation et en supposant
    que $|\hat{\rho}(1)| < 1$ et $|\hat{\theta}| < 1$, on obtient
    \begin{displaymath}
      \hat{\theta} = \frac{1 - \sqrt{1 - 4 \hat{\rho}(1)^2}}{2
        \hat{\rho}(1)}.
    \end{displaymath}
  \end{sol}
\end{exercice}

\begin{exercice}
  \begin{enumerate}
  \item Calculer la fonction d'autocovariance $\gamma(\cdot)$ de la
    série stationnaire
    \begin{displaymath}
      X_t = \mu + Z_t + \theta_1 Z_{t-1} + \theta_{12} Z_{t-12}, \quad
      \{Z_t\} \sim \text{WN}(0, \sigma^2).
    \end{displaymath}
  \item Calculer la moyenne et les autocovariances empiriques
    $\hat{\gamma}(h)$, $0 \leq h \leq 20$ de $\{\nabla \nabla_{12}
    X_t\}$, où $\{X_t, t = 1, \dots, 72\}$ est la série du nombre de
    morts accidentelles \texttt{deaths.dat}.
  \item En égalant les valeurs de $\hat{\gamma}(1)$,
    $\hat{\gamma}(11)$ et $\hat{\gamma}(12)$ trouvées en b) à
    $\gamma(1)$, $\gamma(11)$ et $\gamma(12)$, respectivement, de la
    partie a), trouver un modèle de la forme en a) pour la série
    $\{\nabla \nabla_{12} X_t\}$.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item Par définition de la fonction d'autocovariance,
      \begin{align*}
        \gamma_X(h)
        &= \Cov(X_t, X_{t+h}) \\
        &=
        \begin{cases}
          (1 + \theta_1^2 + \theta_{12}^2) \sigma^2 & h = 0 \\
          \theta_1 \sigma^2                         & h = \pm 1 \\
          \theta_1 \theta_{12} \sigma^2             & h = \pm 11 \\
          \theta_{12} \sigma^2                      & h = \pm 12.
        \end{cases}
      \end{align*}
    \item On a
<<echo=FALSE>>=
deaths <- ts(scan("deaths.dat", comment.char="#"),
             start = 1973, frequency = 12)
@
<<echo=TRUE>>=
y <- diff(diff(deaths, lag = 12))
mean(y)
acf(y, lag.max = 12, type = "covariance", plot = FALSE)$acf
@
<<echo=FALSE>>=
g <- acf(y, lag.max = 12, type = "covariance", plot = FALSE)$acf
mu <- signif(mean(y), 4)
theta1 <- signif(g[12]/g[13], 4)
theta12 <- signif(g[12]/g[2], 4)
s2 <- signif(g[2] * g[13]/g[12], 4)
@
    \item En suivant la procédure mentionnée dans l'énoncé, on obtient
      les estimateurs des paramètres $\theta_1$, $\theta_{12}$ et
      $\sigma^2$ suivants:
      \begin{align*}
        \hat{\theta}_1
        &= \frac{\hat{\gamma}(11)}{\hat{\gamma}(12)} =
        \Sexpr{format(theta1, dec = ",")} \\
        \hat{\theta}_{12}
        &= \frac{\hat{\gamma}(11)}{\hat{\gamma}(1)} =
        \Sexpr{format(theta12, dec = ",")} \\
        \hat{\sigma}^2
        &= \frac{\hat{\gamma}(1) \hat{\gamma}(12)}{\hat{\gamma}(11)} =
        \nombre{\Sexpr{s2}}.
      \end{align*}
      Un modèle pour la série $\{\nabla \nabla_{12} X_t\}$ est donc
      \begin{displaymath}
        \nabla \nabla_{12} X_t =
        \Sexpr{format(mu, dec = ",")} +
        Z_t \Sexpr{format(theta1, dec = ",")} Z_{t-1}
        \Sexpr{format(theta12, dec = ",")} Z_{t-12},
      \end{displaymath}
      où $\{Z_t\} \sim \text{WN}(0, \nombre{\Sexpr{s2}})$.
    \end{enumerate}
  \end{sol}
  \begin{rep}
    \begin{inparaenum}
      \stepcounter{enumi}
      \stepcounter{enumi}
    \item $\nabla \nabla_{12} X_t = \Sexpr{format(mu, dec = ",")} +
      Z_t \Sexpr{format(theta1, dec = ",")}
      Z_{t-1} \Sexpr{format(theta12, dec = ",")} Z_{t-12}$,
      $\{Z_t\} \sim \text{WN}(0, \nombre{\Sexpr{s2}})$
    \end{inparaenum}
  \end{rep}
\end{exercice}

\begin{exercice}
  Soit le processus AR(2) défini comme la solution stationnaire de
  \begin{displaymath}
    X_t - \phi X_{t-1} - \phi^2 X_{t-2} = Z_t,
    \quad \{Z_t\} \sim \text{WN}(0, \sigma^2).
  \end{displaymath}
  \begin{enumerate}
  \item Pour quelles valeurs de $\phi$ une solution stationnaire
    existe-t-elle?
  \item Les estimateurs des moments suivants ont été obtenus après
    l'observation de $X_1, \dots, X_{200}$:
    \begin{displaymath}
      \hat{\gamma}(0) = 6,06, \quad
      \hat{\rho}(1) = 0,687,  \quad
      \hat{\rho}(2) = 0,610.
    \end{displaymath}
    Trouver des estimateurs de $\phi$ et $\sigma^2$ à l'aide des
    équations de Yule--Walker. (Si vous trouvez plus d'une solution,
    retenir celle qui est stationnaire.)
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
    \item $(1 - \sqrt{5})/2 < \phi < (-1 + \sqrt{5})/2$
    \item $\hat{\phi} = 0,509$, $\hat{\sigma}^2 = 2,983$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On sait que le processus AR$(2)$ est stationnaire si
      \begin{align*}
        \phi_2 + \phi_1 &< 1 \\
        \phi_2 - \phi_1 &< 1 \\
        -1 < \phi_2 &< 1.
      \end{align*}
      Dans le présent cas où $\phi_1 = \phi$ et $\phi_2 = \phi^2$,
      sera stationnaire si
      \begin{align*}
        \phi^2 + \phi &< 1 \\
        \phi^2 - \phi &< 1 \\
        -1 < \phi^2 &< 1.
      \end{align*}
      On vérifie alors aisément que les trois inégalités sont
      satisfaites dès lors que
      \begin{displaymath}
        \frac{1 - \sqrt{5}}{2} < \phi < \frac{-1 + \sqrt{5}}{2}.
      \end{displaymath}
    \item Il y a seulement deux paramètres à estimer dans ce modèle
      AR$(2)$ spécial. Les estimateurs de Yule--Walker des paramètres
      $\phi$ et $\sigma^2$ sont les solutions de ce système
      d'équations:
      \begin{align*}
        \hat{\rho}(1)
        &= \hat{\phi} + \hat{\phi}^2 \hat{\rho}(1) \\
        \hat{\sigma}^2
        &= \hat{\gamma}(0)(1 - \hat{\phi} \hat{\rho}(1)
        - \hat{\phi}^2 \hat{\rho}(2)).
      \end{align*}
      Or, en utilisant les valeurs de $\hat{\gamma}(0)$, $\hat{\rho}(1)$ et
      $\hat{\rho}(2)$ fournies dans l'énoncé et en choisissant la
      solution stationnaire, on obtient
      \begin{align*}
        \hat{\phi}    &= 0,509 \\
        \hat{\sigma}^2 &= 2,983.
      \end{align*}
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  On vous donne ci-dessous les valeurs (arrondies) des fonctions
  d'autocovariance et d'autocorrélation partielle empiriques d'un
  processus stationnaire.

<<echo=FALSE>>=
set.seed(123)
X <- ts(arima.sim(list(ar = c(-0.55, 0.4), sd = 1.5), 300));
@

  \begin{minipage}{0.35\textwidth}
<<echo=TRUE>>=
acvf <- acf(X, type="covariance", lag.max=9)
cbind(h=acvf$lag, "gamma(h)"=round(acvf$acf, 2))
@
  \end{minipage}
  \hfill
  \begin{minipage}{0.63\textwidth}
    \mbox{} \\[8mm]
<<echo=FALSE, fig=TRUE>>=
acf(X, main = "")
@
  \end{minipage}

  \begin{minipage}{0.35\textwidth}
<<echo=TRUE>>=
pacf <- acf(X, type="partial", lag.max=10)
cbind(h=pacf$lag, "phi_hh"=round(pacf$acf, 2))
@
  \end{minipage}
  \hfill
  \begin{minipage}{0.63\textwidth}
    \mbox{} \\[8mm]
<<echo=FALSE, fig=TRUE>>=
pacf(X, main = "")
@
  \end{minipage}
  \begin{enumerate}
  \item Trouver un modèle adéquat pour ce processus étant donné les
    informations ci-dessus. Justifier votre réponse.
  \item Trouver des estimateurs des moments pour tous les paramètres
    du modèle proposé en a).
  \end{enumerate}
<<echo=FALSE>>=
g0 <- round(acvf$acf[1], 2)
g1 <- round(acvf$acf[2], 2)
g2 <- round(acvf$acf[3], 2)
X.ar2 <- ar(X)
phi1 <- signif(X.ar2$ar[1], 4)
phi2 <- signif(X.ar2$ar[2], 4)
s2 <-   signif(X.ar2$var.pred, 4)
@
  \begin{rep}
    \begin{inparaenum}
    \item AR$(2)$
    \item $\hat{\phi}_1= \Sexpr{format(phi1, dec = ",")}$,
      $\hat{\phi}_2 = \Sexpr{format(phi2, dec = ",")}$,
      $\hat{\sigma}^2 = \Sexpr{format(s2, dec = ",")}$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item La FACP tombe (statistiquement) à zéro après un pas de 2,
      donc le processus est un AR$(2)$.
    \item Par les équations de Yule--Walker,
      \begin{align*}
        \gamma(1)
        &= \phi_1 \gamma(0) + \phi_2 \gamma(1) \\
        \gamma(2)
        &= \phi_1 \gamma(1) + \phi_2 \gamma(0) \\
        \intertext{et}
        \sigma^2
        &= \gamma(0) - \phi_1 \gamma(1) - \phi_2 \gamma(2).
      \end{align*}
      En remplaçant les valeurs de la FACV par
      $\hat{\gamma}(0) = \Sexpr{format(g0, dec = ",")}$,
      $\hat{\gamma}(1) = \Sexpr{format(g1, dec = ",")}$ et
      $\hat{\gamma}(2) = \Sexpr{format(g2, dec = ",")}$,
      puis en résolvant le système d'équations linéaires, on obtient:
      $\hat{\phi}_1= \Sexpr{format(phi1, dec = ",")}$,
      $\hat{\phi}_2 = \Sexpr{format(phi2, dec = ",")}$ et
      $\hat{\sigma}^2 = \Sexpr{format(s2, dec = ",")}$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\newpage

\begin{exercice}
  Trouver l'autocorrélation partielle de pas 3, $\phi_{33}$, à l'aide
  des informations suivantes:
  \begin{center}
    \begin{tabular}{rccccc}
      \toprule
      $t$ & 1 & 2 & 3 & 4 & 5 \\
      \midrule
      $X_t$ & 2,2 & 1,2 & 2,4 & 4,1 & 3,0 \\
      \bottomrule
    \end{tabular}
  \end{center}
<<echo=FALSE>>=
X <- ts(c(2.2, 1.2, 2.4, 4.1, 3.0))
@
<<echo=TRUE>>=
ar(X, aic = FALSE, order.max = 1)
ar(X, aic = FALSE, order.max = 2)
ar(X, aic = FALSE, order.max = 3)
@
<<echo=FALSE>>=
phi33 <- signif(ar(X, aic = FALSE, order.max = 3)$ar[3], 3)
@
  \begin{rep}
    $\Sexpr{format(phi33, dec = ",")}$
  \end{rep}
  \begin{sol}
    L'autocorrélation partielle de pas 3 correspond à la valeur de
    $\phi_3$ lorsque l'on ajuste un modèle AR$(3)$ aux données. Cette
    valeur est donnée dans le troisième appel de la fonction
    \texttt{ar}. On a donc directement $\phi_{33} =
    \Sexpr{format(phi33, dec = ",")}$.
  \end{sol}
\end{exercice}

\begin{exercice}
  Les estimateurs de Yule--Walker sont sans biais. Vérifier si cette
  affirmation est vraie pour un modèle AR(2) par la petite expérience
  suivante.
  \begin{enumerate}[i)]
  \item Choisir des valeurs pour les paramètres du modèle
    \begin{displaymath}
      X_t - \phi_1 X_{t-1} - \phi_2 X_{t-2} = Z_t,
      \quad \{Z_t\} \sim \text{WN}(0, \sigma^2).
    \end{displaymath}
  \item Simuler 200 observations d'un processus AR(2) avec les
    paramètres choisis en i).
  \item Calculer et sauvegarder les estimateurs de Yule--Walker des
    paramè\-tres (utiliser la fonction \texttt{ar} avec
    \texttt{order.max = 2}).
  \item Répéter les étapes ii) et iii) un grand nombre de fois (au
    moins 1000).
  \item Calculer la moyenne des estimateurs de chaque paramètre.
  \end{enumerate}
  Comparer les valeurs obtenues en v) aux vraies valeurs choisies en
  i). Quelle est votre conclusion?
  \begin{rep}
    Biais négatif
  \end{rep}
  \begin{sol}
    On peut faire l'expérience avec les quelques lignes de codes suivantes:
<<echo=TRUE>>=
f <- function(ar)
{
    ar(arima.sim(n = 200, model = list(ar = ar)),
       aic = FALSE, order.max = 2)$ar
}
rowMeans(replicate(1000, f(c(0.3, 0.6))))
@
    Selon ces résultats, les estimateurs de Yule--Walker sont
    légèrement biaisés négativement.
  \end{sol}
\end{exercice}

\Closesolutionfile{solutions}
\Closesolutionfile{reponses}

%%%
%%% Insérer les réponses
%%%
\input{reponses-estimation}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "exercices_methodes_statistiques"
%%% End:
