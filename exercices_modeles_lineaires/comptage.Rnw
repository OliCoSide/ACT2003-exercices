\chapter{Modélisation de données de comptage}
\label{chap:comptage}

\Opensolutionfile{reponses}[reponses-comptage]
\Opensolutionfile{solutions}[solutions-comptage]

\begin{Filesave}{reponses}
\bigskip
\section*{Réponses}

\end{Filesave}

\begin{Filesave}{solutions}
\section*{Chapitre \ref{chap:comptage}}
\addcontentsline{toc}{section}{Chapitre \protect\ref{chap:comptage}}

\end{Filesave}


\begin{exercice}
Ajuster un modèle de Poisson avec lien logarithmique au données \texttt{esoph} du package \texttt{datasets} en \textsf{R}. À partir du modèle avec effets principaux et les interactions de second ordre 

\texttt{agegp+alcgp+tobgp+agegp:alcgp+agegp:tobgp+alcgp:tobg}, faire une analyse de déviance pour trouver le modèle le plus approprié. Y a-t-il une interaction qui est significative dans le modèle? Expliquer.

\begin{sol}
On ajuste d'abord le modèle avec les effets principaux et les interactions.
<<>>=
library(datasets)
fit1 <- glm(ncases~factor(agegp)*(factor(alcgp)+factor(tobgp))
           +factor(alcgp):factor(tobgp), family=poisson, data=esoph)
anova(fit1)
qchisq(0.95,9) ## rejette alcgp:tobgp
qchisq(0.95,15) ## rejette agegp:tobgp mais conserve agegp:alcgp
@
On trouve donc que l'interaction entre la consommation d'alcool et de tabac n'est pas significative parce que 
\begin{align*}
\Delta Deviance = 7.658 < \chi^{2}_{(9;0.95)}=16.92.
\end{align*}
Cela signifie que le modèle \texttt{agegp*(alcgp+tobgp)} est une simplification adéquate du modèle 
\texttt{agegp+alcgp+tobgp+agegp.alcgp+agegp.tobgp+alcgp.tobgp}. De plus, on peut enlever l'interaction entre l'âge et la consommation de tabac:
\begin{align*}
\Delta Deviance = 18.109 < \chi^{2}_{(15;0.95)}=25.
\end{align*}
Cela signifie que le modèle \texttt{agegp*alcgp+tobgp} est une simplification adéquate du modèle 
\texttt{agegp*(alcgp+tobgp)}. Toutefois, on ne peut pas enlever l'autre terme d'interaction car
\begin{align*}
\Delta Deviance = 32.417 > \chi^{2}_{(15;0.95)}=25.
\end{align*}
Si on tente de remettre l'interaction entre la consommation d'alcool et de tabac dans le modèle, on trouve qu'elle n'est toujours pas significative:
<<>>=
fit2 <- glm(ncases ~ agegp * alcgp + tobgp,family=poisson,data=esoph)
fit3 <- update(fit1,~.-factor(agegp):factor(tobgp))
anova(fit2,fit3)
@
Par conséquent, le modèle final est \texttt{agegp*alcgp+tobgp}. Cela signifie que l'effet de consommer de l'alcool sur l'occurence du cancer de l'oesophage est différent pour chaque groupe d'âge.
\end{sol}
\end{exercice}

\begin{exercice}
Montrer que si $Y|Z=z\sim Poisson(\mu z)$, et $Z\sim Gamma(\theta_z,\theta_z)$, alors $Y\sim BinNeg(\mu,\theta_z)$, soit 
$$
f(y)=\frac{\Gamma(\theta_z+y)}{\Gamma(\theta_z)y!}\left(\frac{\mu}{\mu+\theta_z}\right)^y\left(\frac{\theta_z}{\mu+\theta_z}\right)^{\theta_z}, y=0,1,\ldots
$$
\begin{sol}
On doit intégrer la densité conditionnelle Poisson sur $z$.

On veut prouver que $Y \sim \text{BinNeg}(\mu, \theta_{z})$ avec la fonction de densité suivante:
\begin{align*}
	f_{Y}(y)
	&=	\int_{0}^{\infty} f_{Y|Z = z}(y | z) \cdot g_{Z}(z) dz	\\
	&=	\int_{0}^{\infty} \frac{(\mu z)^{y} e^{-\mu z}}{y!} \cdot \frac{z^{\theta_{z} - 1} \theta_{z}^{\theta_{z}} e^{-\theta_{z} z}}{\Gamma(\theta_{z})} dz	\\
	&=	\frac{(\theta_{z} + y - 1)!}{(\theta_{z} + y - 1 - y)! y!} \cdot \frac{\theta_{z}^{\theta_{z}} \mu^{y}}{(\mu + \theta_{z})^{\theta_{z} + y}}
			\underset{1}{\underbrace{\int_{0}^{\infty} \frac{z^{\theta_{z} + y - 1} \textrm{e}^{-(\mu + \theta_{z})z}}{\Gamma(\theta_{z} + y)} (\mu + \theta_{z})^{\theta_{z} + y} dz}}	
\end{align*}

On trouve donc que 
\begin{align*}			
f_{Y}(y)
	&=	\binom{\theta_{z} + y - 1}{y} \left(\frac{\mu}{\mu + \theta_{z}}\right)^y \left(\frac{\theta_{z}}{\mu + \theta_{z}}\right)^{\theta_{z}}	\\
	&=	\frac{\Gamma(\theta_{z} + y)}{\Gamma(\theta_z) y!} \left(\frac{\mu}{\mu + \theta_{z}}\right)^y \left(\frac{\theta_{z}}{\mu + \theta_{z}}\right)^{\theta_{z}}.
\end{align*}

Et donc, $Y \sim \text{BinNeg}(\mu, \theta_{z})$ où $y \in \{0,1,\ldots\}$.
\end{sol}
\end{exercice}

\begin{exercice}
On suppose que $Y_i$ suit une Poisson avec $g(\mu_i)=\beta_0+\beta_1x_i,$ où $x_i=1,$ pour $i=1,\ldots,n_A$ (groupe A) et $x_i=0,$ pour $i=n_A+1,\ldots,n_A+n_B$ (groupe B). Montrer que, pour toute fonction de lien $g$ continue, l'estimation du GLM par maximum de vraisemblance implique que les moyennes ajustées $\hat{\mu}_A$ et $\hat{\mu}_B$ sont égales aux moyennes empiriques dans l'échantillon. 

\emph{Indice:} La dérivée de la réciproque d'une fonction continue $g$ est $\frac{1}{g'\circ g^{-1}}$.
\begin{sol}
On note $n=n_A+n_B$. La vraisemblance pour ce GLM est
\begin{align*}
\mathcal{L}(\beta_0,\beta_1)&=\prod_{i=1}^n \exp(y_i\log(\mu_i)-\mu_i+\mbox{cte})\\
&=\prod_{i=1}^n \exp(y_i\log(g^{-1}(\eta_i))-g^{-1}(\eta_i)+\mbox{cte}).
\end{align*}
La log-vraisemblance est donc:
\begin{align*}
\ell(\beta_0,\beta_1)&=\sum_{i=1}^n (y_i\log(g^{-1}(\eta_i))-g^{-1}(\eta_i)+\mbox{cte}).
\end{align*}
On dérive par rapport à $\beta_0$ et $\beta_1$:
\begin{align*}
\frac{\partial \ell(\beta_0,\beta_1)}{\partial\beta_0}&=\sum_{i=1}^n (y_i\frac{1}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}-\frac{1}{g'(g^{-1}(\eta_i))})\\
&=\sum_{i=1}^n \frac{(y_i-g^{-1}(\eta_i))}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}\\
\frac{\partial \ell(\beta_0,\beta_1)}{\partial\beta_1}&=\sum_{i=1}^n (y_i\frac{x_i}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}-\frac{x_i}{g'(g^{-1}(\eta_i))})\\
&=\sum_{i=1}^n \frac{ x_i(y_i-g^{-1}(\eta_i))}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}.
\end{align*}
On égalise à 0 pour obtenir le système d'équations à résoudre.
\begin{align*}
0&=\sum_{i=1}^n \frac{(y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}\\
0&=\sum_{i=1}^n \frac{ x_i(y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}
\end{align*}
On utilise que $x_i=0 \forall i \in (n_A+1,...,n_A+n_B)$: 
\begin{align*}
0&=\sum_{i=1}^{n_A+n_B} \frac{(y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}\\
0&=\sum_{i=1}^{n_A} \frac{ (y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}\\
\Rightarrow 0&= \sum_{i=n_A+1}^{n_A+n_B} \frac{ (y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}.
\end{align*}
Aussi, $\forall i \in (1,...,n_A), \hat{\eta}_i=\hat{\beta}_0+\hat{\beta}_1$, ce qui ne dépend pas de $i$. Le dénominateur ne dépend pas de $i$ et peut sortir de la somme et s'annuler. De même, $\forall i \in (n_A+1,...,n_A+n_B), \hat{\eta}_i=\hat{\beta}_0$, ce qui ne dépend pas de $i$. Le dénominateur ne dépend pas de $i$ et peut sortir de la somme et s'annuler. On obtient donc les équations:
\begin{align*}
0&=\sum_{i=1}^{n_A} (y_i-g^{-1}(\hat{\eta}_i))\\
0&= \sum_{i=n_A+1}^{n_A+n_B}  (y_i-g^{-1}(\hat{\eta}_i)).
\end{align*}
Finalement, $g^{-1}(\hat{\eta}_i)=\hat{\mu}_i$ par définition. Alors
\begin{align*}
0&=\sum_{i=1}^{n_A} (y_i-\hat{\mu}_A) \Rightarrow \sum_{i=1}^{n_A}y_i =n_A\hat{\mu}_A \Rightarrow \frac{\sum_{i=1}^{n_A}y_i}{n_A} =\hat{\mu}_A\\
0&= \sum_{i=n_A+1}^{n_A+n_B}  (y_i-\hat{\mu}_B) \Rightarrow \sum_{i=n_A+1}^{n_A+n_B}y_i =n_B\hat{\mu}_B \Rightarrow \frac{\sum_{i=n_A+1}^{n_A+n_B}y_i}{n_B} =\hat{\mu}_B.
\end{align*}
\end{sol}
\end{exercice}

\begin{exercice}
Dans une expérience, on s'intéresse au taux d'imperfection pour deux procédés utilisés pour fabriquer des plaquettes de silicium dans des puces électroniques. Le traitement A a été appliqué pour dix plaquettes et les nombres d'imperfections sont
$$
8, 7, 6, 6, 3, 4, 7, 2, 3, 4.
$$
Le traitement B a été appliqué sur dix autres plaquettes et les nombres d'imperfections sont 
$$
9, 9, 8, 14, 8, 13, 11, 5, 7, 6.
$$ 
On traite les données de comptage comme des variables Poisson indépendantes, avec moyennes $\mu_A$ et $\mu_B$.\footnote{Cet exercice est tiré de Agresti (2013).}

\begin{enumerate}
\item Ajuster le modèle $$\log(\mu_i)=\beta_0+\beta_1 x_i,$$ où $$x_i=\left\{\begin{array}{ll}
0, & \mbox{ si traitement A},\\
1, & \mbox{ si traitement B}.\\
\end{array}\right.
$$ 
Montrer que $\exp(\beta_1)=\mu_B/\mu_A$ et interpréter la valeur de l'estimateur du paramètre.

\item Tester $H_0: \mu_A = \mu_B$ avec le test de Wald. Iterpréter.

\item Construire un intervalle de confiance à 95\% pour $\mu_B/\mu_A$.

\item Y a-t-il présence de surdispersion? Expliquer.

\item Ajuster le modèle Binomiale Négative avec lien logarithmique. Que peut-on remarquer?

\item Ajuster les modèles Poisson et Binomiale Négative aux 20 données sans inclure la variable explicative $x$. Comparer les résultats et comparer les intervalles de confiance pour la moyenne de la variable réponse. Commenter.
\end{enumerate}
\begin{sol}
\begin{enumerate}
\item Avec ce modèle, on a que
\begin{align*}
\mu_A &= \exp(\beta_0)\\
\mu_B &= \exp(\beta_0+\beta_1)=\mu_A \exp(\beta_1),
\end{align*} ce qui implique que $\exp(\beta_1)=\mu_B/\mu_A$. On ajuste le modèle en \texttt{R}, et on vérifie que cela est bien vrai:
<<>>=
y <- c( 8,7,6,6,3,4,7,2,3,4,9,9,8,14,8,13,11,5,7,6)
x <- rep(0:1,each=10)
fit1 <- glm(y~x,family=poisson)
summary(fit1)
log(mean(y[which(x==1)])/mean(y[which(x==0)]))
@

\item Puisque $\exp(\beta_1)=\mu_B/\mu_A$, alors si $H_0: \mu_A=\mu_B$ est vraie, $\beta_1=0$. On peut utiliser la statistique de Wald directement, on trouve que le seuil observé du test est 0.000861. On rejette donc l'hypothèse nulle à un niveau de confiance de 99\%, ce qui implique que les moyennes diffèrent de façon significative.

\item Un I.C. à 95\% pour $\beta_1$ est 
<<>>=
fit1$coef[2]+c(-1,1)*qnorm(0.975)*summary(fit1)$coefficients[2,2]
@

Alors, un I.C. pour $\mu_B/\mu_A$ est $(\exp(0.2421),\exp(0.93349))=(1.273899 , 2.543373)$.

\item Il n'y a pas d'indications de surdispersion, puisque la déviance est 16.26 sur 18 degrés de liberté, et $16.26/18<1$.

\item Quand on ajuste une binomiale négative à ces données, on trouve que $\theta_z$ tend vers l'infini, donc le modèle Poisson est une simplification adéquate du modèle NB. En fait, les estimations des paramètres $\beta_0$ et $\beta_1$ sont exactement les mêmes que celles obtenues dans le modèle Poisson.
<<>>=
library(MASS)
fit2 <- glm.nb(y~x)
summary(fit2)
@

\item Dans ce cas, on remarque que, bien que l'estimation du paramètre est égale pour les deux modèles, l'écart-type diffère. Aussi, le modèle de Poisson ne semble plus adéquat, car $Deviance/dl=27.857/19>1$, alors que le modèle NB s'ajuste bien aux données. Cela montre que lorsqu'une variable explicative importante n'est pas observée, le modèle de Poisson peut perdre sa validité pour des données de comptage. La variable explicative manquante introduit de la sur-dispersion dans les données, ce qui est capturé efficacement avec la loi NB. 
<<>>=
fit3 <- glm(y~1,family=poisson)
fit4 <- glm.nb(y~1)
summary(fit3)
summary(fit4)
exp(fit3$coef[1]+c(-1,1)*qnorm(0.975)*summary(fit3)$coefficients[1,2])
exp(fit4$coef[1]+c(-1,1)*qnorm(0.975)*summary(fit4)$coefficients[1,2])
@
 
\end{enumerate}
\end{sol}
\end{exercice}

\begin{exercice}
Le tableau~\ref{tab:comptage:etudiants} dénombre les applications aux études graduées à l'Université Berkeley en Californie, pour l'automne 1973. On y voit les décisions d'admission par sexe et par département.
\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
 & \multicolumn{2}{c|}{Hommes} & \multicolumn{2}{c|}{Femmes} \\ 
Département & Admis & Non admis & Admis & Non admis\\ \hline
A & 512 & 313 & 89 & 19\\
B    &353  &     207    &      17    &        8  \\
C   & 120  &     205    &     202    &      391  \\
D  &  138  &     279    &     131    &      244  \\
E &    53  &     138    &      94    &      299  \\
F&     22  &     351    &      24    &      317  \\
\hline
\end{tabular}
\caption{Données pour l'exercice sur les admissions aux études graduées. Source: P. Bickel et al. (1975). \emph{Science} $\mathbf{187}: 398-403$.}\label{tab:comptage:etudiants}
\end{center}
\end{table}

\begin{enumerate}
\item Effectuer une régression Poisson avec lien canonique sur le nombre de personnes admises, en utilisant le logarithme du nombre total de personnes qui ont appliqué comme terme offset. Si on utilise seulement le sexe comme variable explicative, est-ce que le sexe a un impact significatif sur le taux d'acceptation?

\item Si on ajoute le département comme variable explicative dans le modèle en a), est-ce que le sexe a toujours un impact significatif sur le taux d'acceptation? Qu'est-ce que cela signifie?

\item Est-ce que l'intéraction entre le sexe et le département est une variable significative dans le modèle? Que peut-on conclure?

\item Est-ce que le modèle Poisson est adéquat pour ces données? Utiliser la déviance et la statistique de Pearson.

\item Refaire les questions a) à c) en utilisant un modèle binomial avec lien logistique, en supposant que $m_i$ est le nombre total de personnes qui ont appliqué.
\end{enumerate}
\begin{sol}
\begin{enumerate}
\item On y va
<<>>=
sex <- rep(0:1,each=6)
Dep <- rep(0:5,2)
y <- c(512,353,120,138,53,22,89,17,202,131,94,24)
no <- c(313,207,205,279,138,351,19,8,391,244,299,317)
nb <- y+no
fitpSex <- glm(y~factor(sex)+offset(log(nb)),family=poisson)
summary(fitpSex)
@

On trouve donc que la valeur-$p$ du test de Wald $H_0: \beta^{SEX}=0$ est $8.15\times10^{-14}$ ce qui est hautement significatif. Puisque le coefficient est négatif et que le niveau de base utilisé est ``hommes'', cela signifie que les femmes ont moins de chance d'être acceptées aux études graduées que les hommes.

\item On ajoute le département:
<<>>=
fitp2 <- glm(y~factor(sex)+factor(Dep)+offset(log(nb)),family=poisson)
summary(fitp2)
@

Dans ce modèle, le résultat du test de Wald pour le coefficient de la variable Sexe est différent. Puisque le seuil observé du test est 34.5\%, on ne peut pas rejeter l'hypothèse nulle que $\beta^{SEX}=0$. Cela signifie que le sexe n'est pas un facteur qui influence le taux d'admission aux études graduées lorsqu'on prend en considération le département. Il en est ainsi car les femmes appliquent plus souvent que les hommes dans des départements où il est plus difficile d'être admis.

\item À l'aide de l'analyse de la déviance, on trouve que l'interaction n'est pas significative:
$$\Delta Deviance = 6.67 < \chi^2 (0.95,5) = 11.07.$$
<<>>=
fitp <- glm(y~factor(sex)*factor(Dep)+offset(log(nb)),family=poisson)
anova(fitp)
qchisq(0.95,5) ## reject interaction
@

\item Le modèle final est celui avec une seule variable explicative dichotomique: le département. La déviance pour ce modèle est 7.5706, ce qui est légèrement supérieur à 6, le nombre de degrés de liberté. Toutefois, puisque $Deviance/dl\approx1.26$, cela n'est pas très alarmant, et il n'y a pas de raison de supposer que le modèle de Poisson est inadéquat. La statistique de Pearson est  8.03, ce qui est aussi une valeur attendue pour la loi chi-carrée avec 6 degrés de liberté.
<<>>=
fitpDep <- glm(y~factor(Dep)+offset(log(nb)),family=poisson)
summary(fitpDep)
sum((y-fitted(fitpDep))^2/fitted(fitpDep))
pchisq(8.025236,6)
@

\item On recommence et on obtient exactement les mêmes conclusions:
<<>>=
fitbSex <- glm(cbind(y,nb-y)~factor(sex),family=binomial)
summary(fitbSex)
fitb2 <- glm(cbind(y,nb-y)~factor(sex)+factor(Dep),family=binomial)
summary(fitb2)
fitb <- glm(cbind(y,nb-y)~factor(sex)*factor(Dep),family=binomial)
anova(fitb)
qchisq(0.95,5)
@
\end{enumerate}
\end{sol}
\end{exercice}

\begin{exercice}
Le fichier de données \texttt{MNLung.csv} (séparé avec des virgules) contient des données sur le nombre de décès dûs au cancer du poumon dans 87 régions au Minnesota, pour les hommes et les femmes. L'objectif de l'étude pour laquelle les données ont été recueillies était d'examiner si l'exposition au gaz radon est relié à un changement dans le taux de morbidité standardisé. La base de données contient sept colonnes:
\begin{description}
\item[County:] Nom de la région;
\item[ID:] Numéro d'identifcation de la région dans la base de données;
\item[YM:] Nombre de décès dûs au cancer du poumon chez les hommes sur une période de 5 ans;
\item[EM:] Espérance du nombre de cas YM, basé sur des facteurs démographiques;
\item[YF:] Nombre de décès dûs au cancer du poumon chez les femmes sur une période de 5 ans;
\item[EF:] Espérance du nombre de cas YF, basé sur des facteurs démographiques;
\item[Radon:] Mesure moyenne de l'exposition au radon dans chaque région pour la période de 5 ans.
\end{description}
Le taux de morbidité standardisé (SMR) pour la région $i$ est défini comme $$SMR_i=\frac{Y_i}{E_i}.$$ En utilisant un modèle linéaire généralisé Poisson approprié, répondre aux question suivantes: 

\begin{enumerate}
\item Y a-t-il des preuves dans ces données que le radon est associé avec un changement dans le SMR ?

\item Y a-t-il une différence entre le SMR pour les hommes et les femmes, lorsque l'on inclut ou pas la variable explicative radon dans le modèle?

\item Donner les prévisions pour le SMR, avec la mesure d'incertitude, pour des hommes dans une région hypothétique où l'exposition moyenne au radon est de 6 unités.

\item Commenter sur la validité du modèle de Poisson pour ces données.
\end{enumerate}

\begin{sol}
<<echo=FALSE>>=
dat <- read.csv("data/MNlung.csv")
attach(dat)
@
\begin{enumerate}
\item If $Y_{i}\sim Poisson(E_{i}\lambda_{i})$, then, using the canonical link, $$\log(\mu_{i})=log(E_{i})+log(\lambda_{i}),$$ where $\lambda_{i}$ is the mean $SMR$ for observation $i$. $\log(E_{i})$, the natural logarithm of the expected count of lung cancer based on the demographics of the county, is passed to the \texttt{glm} function as an offset factor. 

The data for males and females are concatenated to create a model with one covariate, Radon exposure, and one factor predictor, Sex, which takes 2 levels (0 for males and 1 for females).
<<>>=
Ytot <- c(YM,YF)
Etot <- c(EM,EF)
Sex <- c(rep(0,length(YM)),rep(1,length(YF))) ## 1 if female
Radontot <- rep(Radon,2)

modsex <- glm(Ytot~Sex+offset(log(Etot)),family=poisson)
modsexrad <- glm(Ytot~Radontot+Sex+offset(log(Etot)),family=poisson)

anova(modsex,modsexrad)

qchisq(0.99,1)
@

As shown above, the analysis of deviance shows strong evidence that the radon exposure influences the number of lung cancer in a particular county: 
\begin{align*}
\Delta Deviance = 46.22 > \chi^{2}_{(1;0.99)}=6.6349.
\end{align*}

\item The null model and the model including sex only are fitted.
<<>>=
modtot <- glm(Ytot~1+offset(log(Etot)),family=poisson)
modsex <- glm(Ytot~Sex+offset(log(Etot)),family=poisson)
anova(modtot,modsex) 

qchisq(0.95,1)
@
The analysis of deviance shows that $\Delta Deviance= 0.0093398<\chi^{2}_{(1;0.95)}=3.8415$. Hence, the null model is an appropriate simplification of the model including the factor Sex, so the factor is not significant. However, below is the \texttt{R} output for the analysis of deviance when the covariate Radon (known to be significant from a) is included in the model. If we first consider the model with main effects and interactions, we see that $\Delta Deviance= 8.823>\chi^{2}_{(1;0.99)}$, meaning that the model with main effects only is not an adequate simplification of the model with main effects and interactions. Thus, the factor predictor Sex is significant in the model through its interaction with the covariate Radon. Note that even if the main effect of the Sex does not appear to be significant, it is kept in the model by convention.

<<>>=
modtotrad <- glm(Ytot~Radontot+offset(log(Etot)),family=poisson)
modsexrad <- glm(Ytot~Radontot+Sex+offset(log(Etot)),family=poisson)
modsexradINT <- glm(Ytot~Radontot*Sex+offset(log(Etot)),family=poisson)
anova(modtot,modtotrad,modsexrad,modsexradINT)
@

\item The predictions are obtained using the command 
<<echo=TRUE, eval=FALSE>>=
predict(modsexradINT,data.frame(Radontot=6,Sex=0,Etot=1),type="response",se.fit=TRUE)
@
 If the model Sex*Radon is used, we find $$\hat{SMR}_{Sex=0,Radon=6}=0.9708183,$$ with a standard error of 0.01415307.

\item The model Sex*Radon has a deviance of 355.23 on 170 degrees of freedom. A heuristic check for the validity of the model is to calculate the estimated dispersion parameter $$\hat{\phi}=\frac{355.23}{170}=2.089$$ and to compare it with 1, the dispersion parameter implied in the Poisson model. This check suggests the presence of overdispersion in the data as $\hat{\phi}$ is greater than 1. Fitting the quasipoisson model also leads to the same conclusion: the estimated dispersion parameter is 1.98311, closer to 2. Thus, we can conclude that the Poisson model is not adequate, we might consider fitting a Negative Binomial model to capture the overdispersion.
\end{enumerate}
\end{sol}
\end{exercice}


\Closesolutionfile{solutions}
\Closesolutionfile{reponses}

%%%
%%% Insérer les réponses
%%%
\input{reponses-comptage}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "exercices_methodes_statistiques"
%%% End:
