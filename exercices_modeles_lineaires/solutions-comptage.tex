\section*{Chapitre \ref{chap:comptage}}
\addcontentsline{toc}{section}{Chapitre \protect\ref{chap:comptage}}

\begin{solution}{6.1}
On ajuste d'abord le modèle avec les effets principaux et les interactions.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(datasets)}
\hlstd{fit1} \hlkwb{<-} \hlkwd{glm}\hlstd{(ncases}\hlopt{~}\hlkwd{factor}\hlstd{(agegp)}\hlopt{*}\hlstd{(}\hlkwd{factor}\hlstd{(alcgp)}\hlopt{+}\hlkwd{factor}\hlstd{(tobgp))}\hlopt{+}\hlkwd{factor}\hlstd{(alcgp)}\hlopt{:}\hlkwd{factor}\hlstd{(tobgp),}\hlkwc{family}\hlstd{=poisson,}\hlkwc{data}\hlstd{=esoph)}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning: glm.fit: fitted rates numerically 0 occurred}}\begin{alltt}
\hlkwd{anova}\hlstd{(fit1)}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning: glm.fit: fitted rates numerically 0 occurred}}\begin{verbatim}
## Analysis of Deviance Table
##
## Model: poisson, link: log
##
## Response: ncases
##
## Terms added sequentially (first to last)
##
##
##                             Df Deviance Resid. Df
## NULL                                           87
## factor(agegp)                5  138.256        82
## factor(alcgp)                3   24.106        79
## factor(tobgp)                3   22.169        76
## factor(agegp):factor(alcgp) 15   32.417        61
## factor(agegp):factor(tobgp) 15   18.109        46
## factor(alcgp):factor(tobgp)  9    7.658        37
##                             Resid. Dev
## NULL                           262.926
## factor(agegp)                  124.670
## factor(alcgp)                  100.564
## factor(tobgp)                   78.395
## factor(agegp):factor(alcgp)     45.979
## factor(agegp):factor(tobgp)     27.870
## factor(alcgp):factor(tobgp)     20.212
\end{verbatim}
\begin{alltt}
\hlkwd{qchisq}\hlstd{(}\hlnum{0.95}\hlstd{,}\hlnum{9}\hlstd{)} \hlcom{## rejette alcgp:tobgp}
\end{alltt}
\begin{verbatim}
## [1] 16.91898
\end{verbatim}
\begin{alltt}
\hlkwd{qchisq}\hlstd{(}\hlnum{0.95}\hlstd{,}\hlnum{15}\hlstd{)} \hlcom{## rejette agegp:tobgp mais conserve agegp:alcgp}
\end{alltt}
\begin{verbatim}
## [1] 24.99579
\end{verbatim}
\end{kframe}
\end{knitrout}
On trouve donc que l'interaction entre la consommation d'alcool et de tabac n'est pas significative parce que
\begin{align*}
\Delta Deviance = 7.658 < \chi^{2}_{(9;0.95)}=16.92.
\end{align*}
Cela signifie que le modèle \texttt{agegp*(alcgp+tobgp)} est une simplification adéquate du modèle
\texttt{agegp+alcgp+tobgp+agegp.alcgp+agegp.tobgp+alcgp.tobgp}. De plus, on peut enlever l'interaction entre l'âge et la consommation de tabac:
\begin{align*}
\Delta Deviance = 18.109 < \chi^{2}_{(15;0.95)}=25.
\end{align*}
Cela signifie que le modèle \texttt{agegp*alcgp+tobgp} est une simplification adéquate du modèle
\texttt{agegp*(alcgp+tobgp)}. Toutefois, on ne peut pas enlever l'autre terme d'interaction car
\begin{align*}
\Delta Deviance = 32.417 > \chi^{2}_{(15;0.95)}=25.
\end{align*}
Si on tente de remettre l'interaction entre la consommation d'alcool et de tabac dans le modèle, on trouve qu'elle n'est toujours pas significative:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fit2} \hlkwb{<-} \hlkwd{glm}\hlstd{(ncases} \hlopt{~} \hlstd{agegp} \hlopt{*} \hlstd{alcgp} \hlopt{+} \hlstd{tobgp,}\hlkwc{family}\hlstd{=poisson,}\hlkwc{data}\hlstd{=esoph)}
\hlstd{fit3} \hlkwb{<-} \hlkwd{update}\hlstd{(fit1,}\hlopt{~}\hlstd{.}\hlopt{-}\hlkwd{factor}\hlstd{(agegp)}\hlopt{:}\hlkwd{factor}\hlstd{(tobgp))}
\hlkwd{anova}\hlstd{(fit2,fit3)}
\end{alltt}
\begin{verbatim}
## Analysis of Deviance Table
##
## Model 1: ncases ~ agegp * alcgp + tobgp
## Model 2: ncases ~ factor(agegp) + factor(alcgp) + factor(tobgp) + factor(agegp):factor(alcgp) +
##     factor(alcgp):factor(tobgp)
##   Resid. Df Resid. Dev Df Deviance
## 1        61     45.979
## 2        52     38.973  9    7.006
\end{verbatim}
\end{kframe}
\end{knitrout}
Par conséquent, le modèle final est \texttt{agegp*alcgp+tobgp}. Cela signifie que l'effet de consommer de l'alcool sur l'occurence du cancer de l'oesophage est différent pour chaque groupe d'âge.
\end{solution}
\begin{solution}{6.2}
Intégrer la densité conditionnelle Poisson sur $z$. Comme c'est plus agréable à faire à la main qu'à taper, je vous laisse le soin de réussir par vous-même.
\end{solution}
\begin{solution}{6.3}
On note $n=n_A+n_B$. La vraisemblance pour ce GLM est
\begin{align*}
\mathcal{L}(\beta_0,\beta_1)&=\prod_{i=1}^n \exp(y_i\log(\mu_i)-\mu_i+\mbox{cte})\\
&=\prod_{i=1}^n \exp(y_i\log(g^{-1}(\eta_i))-g^{-1}(\eta_i)+\mbox{cte}).
\end{align*}
La log-vraisemblance est donc:
\begin{align*}
\ell(\beta_0,\beta_1)&=\sum_{i=1}^n (y_i\log(g^{-1}(\eta_i))-g^{-1}(\eta_i)+\mbox{cte}).
\end{align*}
On dérive par rapport à $\beta_0$ et $\beta_1$:
\begin{align*}
\frac{\partial \ell(\beta_0,\beta_1)}{\partial\beta_0}&=\sum_{i=1}^n (y_i\frac{1}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}-\frac{1}{g'(g^{-1}(\eta_i))})\\
&=\sum_{i=1}^n \frac{(y_i-g^{-1}(\eta_i))}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}\\
\frac{\partial \ell(\beta_0,\beta_1)}{\partial\beta_1}&=\sum_{i=1}^n (y_i\frac{x_i}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}-\frac{x_i}{g'(g^{-1}(\eta_i))})\\
&=\sum_{i=1}^n \frac{ x_i(y_i-g^{-1}(\eta_i))}{g^{-1}(\eta_i)g'(g^{-1}(\eta_i))}.
\end{align*}
On égalise à 0 pour obtenir le système d'équations à résoudre.
\begin{align*}
0&=\sum_{i=1}^n \frac{(y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}\\
0&=\sum_{i=1}^n \frac{ x_i(y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}
\end{align*}
On utilise que $x_i=0 \forall i \in (n_A+1,...,n_A+n_B)$:
\begin{align*}
0&=\sum_{i=1}^{n_A+n_B} \frac{(y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}\\
0&=\sum_{i=1}^{n_A} \frac{ (y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}\\
\Rightarrow 0&= \sum_{i=n_A+1}^{n_A+n_B} \frac{ (y_i-g^{-1}(\hat{\eta}_i))}{g^{-1}(\hat{\eta}_i)g'(g^{-1}(\hat{\eta}_i))}.
\end{align*}
Aussi, $\forall i \in (1,...,n_A), \hat{\eta}_i=\hat{\beta}_0+\hat{\beta}_1$, ce qui ne dépend pas de $i$. Le dénominateur ne dépend pas de $i$ et peut sortir de la somme et s'annuler. De même, $\forall i \in (n_A+1,...,n_A+n_B), \hat{\eta}_i=\hat{\beta}_0$, ce qui ne dépend pas de $i$. Le dénominateur ne dépend pas de $i$ et peut sortir de la somme et s'annuler. On obtient donc les équations:
\begin{align*}
0&=\sum_{i=1}^{n_A} (y_i-g^{-1}(\hat{\eta}_i))\\
0&= \sum_{i=n_A+1}^{n_A+n_B}  (y_i-g^{-1}(\hat{\eta}_i)).
\end{align*}
Finalement, $g^{-1}(\hat{\eta}_i)=\hat{\mu}_i$ par définition. Alors
\begin{align*}
0&=\sum_{i=1}^{n_A} (y_i-\hat{\mu}_A) \Rightarrow \sum_{i=1}^{n_A}y_i =n_A\hat{\mu}_A \Rightarrow \frac{\sum_{i=1}^{n_A}y_i}{n_A} =\hat{\mu}_A\\
0&= \sum_{i=n_A+1}^{n_A+n_B}  (y_i-\hat{\mu}_B) \Rightarrow \sum_{i=n_A+1}^{n_A+n_B}y_i =n_B\hat{\mu}_B \Rightarrow \frac{\sum_{i=n_A+1}^{n_A+n_B}y_i}{n_B} =\hat{\mu}_B.
\end{align*}
\end{solution}
\begin{solution}{6.4}
\begin{enumerate}
\item Avec ce modèle, on a que
\begin{align*}
\mu_A &= \exp(\beta_0)\\
\mu_B &= \exp(\beta_0+\beta_1)=\mu_A \exp(\beta_1),
\end{align*} ce qui implique que $\exp(\beta_1)=\mu_B/\mu_A$. On ajuste le modèle en \texttt{R}, et on vérifie que cela est bien vrai:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y} \hlkwb{<-} \hlkwd{c}\hlstd{(} \hlnum{8}\hlstd{,}\hlnum{7}\hlstd{,}\hlnum{6}\hlstd{,}\hlnum{6}\hlstd{,}\hlnum{3}\hlstd{,}\hlnum{4}\hlstd{,}\hlnum{7}\hlstd{,}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{,}\hlnum{4}\hlstd{,}\hlnum{9}\hlstd{,}\hlnum{9}\hlstd{,}\hlnum{8}\hlstd{,}\hlnum{14}\hlstd{,}\hlnum{8}\hlstd{,}\hlnum{13}\hlstd{,}\hlnum{11}\hlstd{,}\hlnum{5}\hlstd{,}\hlnum{7}\hlstd{,}\hlnum{6}\hlstd{)}
\hlstd{x} \hlkwb{<-} \hlkwd{rep}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,}\hlkwc{each}\hlstd{=}\hlnum{10}\hlstd{)}
\hlstd{fit1} \hlkwb{<-} \hlkwd{glm}\hlstd{(y}\hlopt{~}\hlstd{x,}\hlkwc{family}\hlstd{=poisson)}
\hlkwd{summary}\hlstd{(fit1)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm(formula = y ~ x, family = poisson)
##
## Deviance Residuals:
##     Min       1Q   Median       3Q      Max
## -1.5280  -0.7622  -0.1699   0.6938   1.5399
##
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)
## (Intercept)   1.6094     0.1414  11.380  < 2e-16 ***
## x             0.5878     0.1764   3.332 0.000861 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for poisson family taken to be 1)
##
##     Null deviance: 27.857  on 19  degrees of freedom
## Residual deviance: 16.268  on 18  degrees of freedom
## AIC: 94.349
##
## Number of Fisher Scoring iterations: 4
\end{verbatim}
\begin{alltt}
\hlkwd{log}\hlstd{(}\hlkwd{mean}\hlstd{(y[}\hlkwd{which}\hlstd{(x}\hlopt{==}\hlnum{1}\hlstd{)])}\hlopt{/}\hlkwd{mean}\hlstd{(y[}\hlkwd{which}\hlstd{(x}\hlopt{==}\hlnum{0}\hlstd{)]))}
\end{alltt}
\begin{verbatim}
## [1] 0.5877867
\end{verbatim}
\end{kframe}
\end{knitrout}

\item Puisque $\exp(\beta_1)=\mu_B/\mu_A$, alors si $H_0: \mu_A=\mu_B$ est vraie, $\beta_1=0$. On peut utiliser la statistique de Wald directement, on trouve que le seuil observé du test est 0.000861. On rejette donc l'hypothèse nulle à un niveau de confiance de 99\%, ce qui implique que les moyennes diffèrent de façon significative.

\item Un I.C. à 95\% pour $\beta_1$ est
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fit1}\hlopt{$}\hlstd{coef[}\hlnum{2}\hlstd{]}\hlopt{+}\hlkwd{c}\hlstd{(}\hlopt{-}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{)}\hlopt{*}\hlkwd{qnorm}\hlstd{(}\hlnum{0.975}\hlstd{)}\hlopt{*}\hlkwd{summary}\hlstd{(fit1)}\hlopt{$}\hlstd{coefficients[}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{]}
\end{alltt}
\begin{verbatim}
## [1] 0.2420820 0.9334913
\end{verbatim}
\end{kframe}
\end{knitrout}

Alors, un I.C. pour $\mu_B/\mu_A$ est $(\exp(0.2421),\exp(0.93349))=(1.273899 , 2.543373)$.

\item Il n'y a pas d'indications de surdispersion, puisque la déviance est 16.26 sur 18 degrés de liberté, et $16.26/18<1$.

\item Quand on ajuste une binomiale négative à ces données, on trouve que $\theta_z$ tend vers l'infini, donc le modèle Poisson est une simplification adéquate du modèle NB. En fait, les estimations des paramètres $\beta_0$ et $\beta_1$ sont exactement les mêmes que celles obtenues dans le modèle Poisson.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(MASS)}
\hlstd{fit2} \hlkwb{<-} \hlkwd{glm.nb}\hlstd{(y}\hlopt{~}\hlstd{x)}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning in theta.ml(Y, mu, sum(w), w, limit = control\$maxit, trace = control\$trace > : iteration limit reached}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning in theta.ml(Y, mu, sum(w), w, limit = control\$maxit, trace = control\$trace > : iteration limit reached}}\begin{alltt}
\hlkwd{summary}\hlstd{(fit2)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm.nb(formula = y ~ x, init.theta = 113420.3107, link = log)
##
## Deviance Residuals:
##     Min       1Q   Median       3Q      Max
## -1.5280  -0.7622  -0.1699   0.6937   1.5398
##
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)
## (Intercept)   1.6094     0.1414  11.380  < 2e-16 ***
## x             0.5878     0.1764   3.332 0.000861 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for Negative Binomial(113420.3) family taken to be 1)
##
##     Null deviance: 27.855  on 19  degrees of freedom
## Residual deviance: 16.267  on 18  degrees of freedom
## AIC: 96.349
##
## Number of Fisher Scoring iterations: 1
##
##
##               Theta:  113420
##           Std. Err.:  4076965
## Warning while fitting theta: iteration limit reached
##
##  2 x log-likelihood:  -90.349
\end{verbatim}
\end{kframe}
\end{knitrout}

\item Dans ce cas, on remarque que, bien que l'estimation du paramètre est égale pour les deux modèles, l'écart-type diffère. Aussi, le modèle de Poisson ne semble plus adéquat, car $Deviance/dl=27.857/19>1$, alors que le modèle NB s'ajuste bien aux données. Cela montre que lorsqu'une variable explicative importante n'est pas observée, le modèle de Poisson peut perdre sa validité pour des données de comptage. La variable explicative manquante introduit de la sur-dispersion dans les données, ce qui est capturé efficacement avec la loi NB.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fit3} \hlkwb{<-} \hlkwd{glm}\hlstd{(y}\hlopt{~}\hlnum{1}\hlstd{,}\hlkwc{family}\hlstd{=poisson)}
\hlstd{fit4} \hlkwb{<-} \hlkwd{glm.nb}\hlstd{(y}\hlopt{~}\hlnum{1}\hlstd{)}
\hlkwd{summary}\hlstd{(fit3)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm(formula = y ~ 1, family = poisson)
##
## Deviance Residuals:
##     Min       1Q   Median       3Q      Max
## -2.2336  -0.9063   0.0000   0.4580   2.3255
##
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)
## (Intercept)  1.94591    0.08451   23.02   <2e-16 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for poisson family taken to be 1)
##
##     Null deviance: 27.857  on 19  degrees of freedom
## Residual deviance: 27.857  on 19  degrees of freedom
## AIC: 103.94
##
## Number of Fisher Scoring iterations: 4
\end{verbatim}
\begin{alltt}
\hlkwd{summary}\hlstd{(fit4)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm.nb(formula = y ~ 1, init.theta = 18.2073559, link = log)
##
## Deviance Residuals:
##     Min       1Q   Median       3Q      Max
## -1.9810  -0.7836   0.0000   0.3859   1.9033
##
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)
## (Intercept)  1.94591    0.09944   19.57   <2e-16 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for Negative Binomial(18.2074) family taken to be 1)
##
##     Null deviance: 20.279  on 19  degrees of freedom
## Residual deviance: 20.279  on 19  degrees of freedom
## AIC: 104.77
##
## Number of Fisher Scoring iterations: 1
##
##
##               Theta:  18.2
##           Std. Err.:  21.0
##
##  2 x log-likelihood:  -100.767
\end{verbatim}
\begin{alltt}
\hlkwd{exp}\hlstd{(fit3}\hlopt{$}\hlstd{coef[}\hlnum{1}\hlstd{]}\hlopt{+}\hlkwd{c}\hlstd{(}\hlopt{-}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{)}\hlopt{*}\hlkwd{qnorm}\hlstd{(}\hlnum{0.975}\hlstd{)}\hlopt{*}\hlkwd{summary}\hlstd{(fit3)}\hlopt{$}\hlstd{coefficients[}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{])}
\end{alltt}
\begin{verbatim}
## [1] 5.931421 8.261090
\end{verbatim}
\begin{alltt}
\hlkwd{exp}\hlstd{(fit4}\hlopt{$}\hlstd{coef[}\hlnum{1}\hlstd{]}\hlopt{+}\hlkwd{c}\hlstd{(}\hlopt{-}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{)}\hlopt{*}\hlkwd{qnorm}\hlstd{(}\hlnum{0.975}\hlstd{)}\hlopt{*}\hlkwd{summary}\hlstd{(fit4)}\hlopt{$}\hlstd{coefficients[}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{])}
\end{alltt}
\begin{verbatim}
## [1] 5.760386 8.506374
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{enumerate}
\end{solution}
\begin{solution}{6.5}
\begin{enumerate}
\item On y va
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{sex} \hlkwb{<-} \hlkwd{rep}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,}\hlkwc{each}\hlstd{=}\hlnum{6}\hlstd{)}
\hlstd{Dep} \hlkwb{<-} \hlkwd{rep}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{5}\hlstd{,}\hlnum{2}\hlstd{)}
\hlstd{y} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{512}\hlstd{,}\hlnum{353}\hlstd{,}\hlnum{120}\hlstd{,}\hlnum{138}\hlstd{,}\hlnum{53}\hlstd{,}\hlnum{22}\hlstd{,}\hlnum{89}\hlstd{,}\hlnum{17}\hlstd{,}\hlnum{202}\hlstd{,}\hlnum{131}\hlstd{,}\hlnum{94}\hlstd{,}\hlnum{24}\hlstd{)}
\hlstd{no} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{313}\hlstd{,}\hlnum{207}\hlstd{,}\hlnum{205}\hlstd{,}\hlnum{279}\hlstd{,}\hlnum{138}\hlstd{,}\hlnum{351}\hlstd{,}\hlnum{19}\hlstd{,}\hlnum{8}\hlstd{,}\hlnum{391}\hlstd{,}\hlnum{244}\hlstd{,}\hlnum{299}\hlstd{,}\hlnum{317}\hlstd{)}
\hlstd{nb} \hlkwb{<-} \hlstd{y}\hlopt{+}\hlstd{no}
\hlstd{fitpSex} \hlkwb{<-} \hlkwd{glm}\hlstd{(y}\hlopt{~}\hlkwd{factor}\hlstd{(sex)}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(nb)),}\hlkwc{family}\hlstd{=poisson)}
\hlkwd{summary}\hlstd{(fitpSex)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm(formula = y ~ factor(sex) + offset(log(nb)), family = poisson)
##
## Deviance Residuals:
##      Min        1Q    Median        3Q       Max
## -14.1129   -3.6826   -0.2719    3.7437    8.0834
##
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)
## (Intercept)  -0.80926    0.02889 -28.011  < 2e-16 ***
## factor(sex)1 -0.38298    0.05128  -7.468 8.15e-14 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for poisson family taken to be 1)
##
##     Null deviance: 551.69  on 11  degrees of freedom
## Residual deviance: 493.56  on 10  degrees of freedom
## AIC: 573.76
##
## Number of Fisher Scoring iterations: 4
\end{verbatim}
\end{kframe}
\end{knitrout}

On trouve donc que la valeur-$p$ du test de Wald $H_0: \beta^{SEX}=0$ est $8.15\times10^{-14}$ ce qui est hautement significatif. Puisque le coefficient est négatif et que le niveau de base utilisé est ``hommes'', cela signifie que les femmes ont moins de chance d'être acceptées aux études graduées que les hommes.

\item On ajoute le département:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fitp2} \hlkwb{<-} \hlkwd{glm}\hlstd{(y}\hlopt{~}\hlkwd{factor}\hlstd{(sex)}\hlopt{+}\hlkwd{factor}\hlstd{(Dep)}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(nb)),}\hlkwc{family}\hlstd{=poisson)}
\hlkwd{summary}\hlstd{(fitp2)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm(formula = y ~ factor(sex) + factor(Dep) + offset(log(nb)),
##     family = poisson)
##
## Deviance Residuals:
##        1         2         3         4         5
## -0.68882  -0.01474   0.96655   0.02569   0.97713
##        6         7         8         9        10
## -0.28371   1.77895   0.06756  -0.71131  -0.02632
##       11        12
## -0.68503   0.28254
##
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)
## (Intercept)  -0.44677    0.04148 -10.771   <2e-16 ***
## factor(sex)1  0.05859    0.06166   0.950    0.342
## factor(Dep)1 -0.01391    0.06625  -0.210    0.834
## factor(Dep)2 -0.63911    0.07660  -8.344   <2e-16 ***
## factor(Dep)3 -0.66125    0.07675  -8.615   <2e-16 ***
## factor(Dep)4 -0.97250    0.09836  -9.887   <2e-16 ***
## factor(Dep)5 -2.32388    0.15468 -15.024   <2e-16 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for poisson family taken to be 1)
##
##     Null deviance: 551.6926  on 11  degrees of freedom
## Residual deviance:   6.6698  on  5  degrees of freedom
## AIC: 96.868
##
## Number of Fisher Scoring iterations: 3
\end{verbatim}
\end{kframe}
\end{knitrout}

Dans ce modèle, le résultat du test de Wald pour le coefficient de la variable Sexe est différent. Puisque le seuil observé du test est 34.5\%, on ne peut pas rejeter l'hypothèse nulle que $\beta^{SEX}=0$. Cela signifie que le sexe n'est pas un facteur qui influence le taux d'admission aux études graduées lorsqu'on prend en considération le département. Il en est ainsi car les femmes appliquent plus souvent que les hommes dans des départements où il est plus difficile d'être admis.

\item À l'aide de l'analyse de la déviance, on trouve que l'interaction n'est pas significative:
$$\Delta Deviance = 6.67 < \chi^2 (0.95,5) = 11.07.$$
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fitp} \hlkwb{<-} \hlkwd{glm}\hlstd{(y}\hlopt{~}\hlkwd{factor}\hlstd{(sex)}\hlopt{*}\hlkwd{factor}\hlstd{(Dep)}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(nb)),}\hlkwc{family}\hlstd{=poisson)}
\hlkwd{anova}\hlstd{(fitp)}
\end{alltt}
\begin{verbatim}
## Analysis of Deviance Table
##
## Model: poisson, link: log
##
## Response: y
##
## Terms added sequentially (first to last)
##
##
##                         Df Deviance Resid. Df
## NULL                                       11
## factor(sex)              1    58.13        10
## factor(Dep)              5   486.89         5
## factor(sex):factor(Dep)  5     6.67         0
##                         Resid. Dev
## NULL                        551.69
## factor(sex)                 493.56
## factor(Dep)                   6.67
## factor(sex):factor(Dep)       0.00
\end{verbatim}
\begin{alltt}
\hlkwd{qchisq}\hlstd{(}\hlnum{0.95}\hlstd{,}\hlnum{5}\hlstd{)} \hlcom{## reject interaction}
\end{alltt}
\begin{verbatim}
## [1] 11.0705
\end{verbatim}
\end{kframe}
\end{knitrout}

\item Le modèle final est celui avec une seule variable explicative dichotomique: le département. La déviance pour ce modèle est 7.5706, ce qui est légèrement supérieur à 6, le nombre de degrés de liberté. Toutefois, puisque $Deviance/dl\approx1.26$, cela n'est pas très alarmant, et il n'y a pas de raison de supposer que le modèle de Poisson est inadéquat. La statistique de Pearson est  8.03, ce qui est aussi une valeur attendue pour la loi chi-carrée avec 6 degrés de liberté.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fitpDep} \hlkwb{<-} \hlkwd{glm}\hlstd{(y}\hlopt{~}\hlkwd{factor}\hlstd{(Dep)}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(nb)),}\hlkwc{family}\hlstd{=poisson)}
\hlkwd{summary}\hlstd{(fitpDep)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm(formula = y ~ factor(Dep) + offset(log(nb)), family = poisson)
##
## Deviance Residuals:
##     Min       1Q   Median       3Q      Max
## -0.8481  -0.4187   0.1160   0.4595   2.2321
##
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)
## (Intercept)  -0.43981    0.04079 -10.782   <2e-16 ***
## factor(Dep)1 -0.01830    0.06608  -0.277    0.782
## factor(Dep)2 -0.60784    0.06906  -8.801   <2e-16 ***
## factor(Dep)3 -0.64004    0.07336  -8.725   <2e-16 ***
## factor(Dep)4 -0.93966    0.09201 -10.212   <2e-16 ***
## factor(Dep)5 -2.30243    0.15298 -15.050   <2e-16 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for poisson family taken to be 1)
##
##     Null deviance: 551.6926  on 11  degrees of freedom
## Residual deviance:   7.5706  on  6  degrees of freedom
## AIC: 95.769
##
## Number of Fisher Scoring iterations: 4
\end{verbatim}
\begin{alltt}
\hlkwd{sum}\hlstd{((y}\hlopt{-}\hlkwd{fitted}\hlstd{(fitpDep))}\hlopt{^}\hlnum{2}\hlopt{/}\hlkwd{fitted}\hlstd{(fitpDep))}
\end{alltt}
\begin{verbatim}
## [1] 8.025236
\end{verbatim}
\begin{alltt}
\hlkwd{pchisq}\hlstd{(}\hlnum{8.025236}\hlstd{,}\hlnum{6}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0.7637397
\end{verbatim}
\end{kframe}
\end{knitrout}

\item On recommence et on obtient exactement les mêmes conclusions:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fitbSex} \hlkwb{<-} \hlkwd{glm}\hlstd{(}\hlkwd{cbind}\hlstd{(y,nb}\hlopt{-}\hlstd{y)}\hlopt{~}\hlkwd{factor}\hlstd{(sex),}\hlkwc{family}\hlstd{=binomial)}
\hlkwd{summary}\hlstd{(fitbSex)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm(formula = cbind(y, nb - y) ~ factor(sex), family = binomial)
##
## Deviance Residuals:
##      Min        1Q    Median        3Q       Max
## -16.7915   -4.7613   -0.4365    5.1025   11.2022
##
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)
## (Intercept)  -0.22013    0.03879  -5.675 1.38e-08 ***
## factor(sex)1 -0.61035    0.06389  -9.553  < 2e-16 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
##     Null deviance: 877.06  on 11  degrees of freedom
## Residual deviance: 783.61  on 10  degrees of freedom
## AIC: 856.55
##
## Number of Fisher Scoring iterations: 4
\end{verbatim}
\begin{alltt}
\hlstd{fitb2} \hlkwb{<-} \hlkwd{glm}\hlstd{(}\hlkwd{cbind}\hlstd{(y,nb}\hlopt{-}\hlstd{y)}\hlopt{~}\hlkwd{factor}\hlstd{(sex)}\hlopt{+}\hlkwd{factor}\hlstd{(Dep),}\hlkwc{family}\hlstd{=binomial)}
\hlkwd{summary}\hlstd{(fitb2)}
\end{alltt}
\begin{verbatim}
##
## Call:
## glm(formula = cbind(y, nb - y) ~ factor(sex) + factor(Dep), family = binomial)
##
## Deviance Residuals:
##       1        2        3        4        5        6
## -1.2487  -0.0560   1.2533   0.0826   1.2205  -0.2076
##       7        8        9       10       11       12
##  3.7189   0.2706  -0.9243  -0.0858  -0.8509   0.2052
##
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)
## (Intercept)   0.58205    0.06899   8.436   <2e-16 ***
## factor(sex)1  0.09987    0.08085   1.235    0.217
## factor(Dep)1 -0.04340    0.10984  -0.395    0.693
## factor(Dep)2 -1.26260    0.10663 -11.841   <2e-16 ***
## factor(Dep)3 -1.29461    0.10582 -12.234   <2e-16 ***
## factor(Dep)4 -1.73931    0.12611 -13.792   <2e-16 ***
## factor(Dep)5 -3.30648    0.16998 -19.452   <2e-16 ***
## ---
## Signif. codes:
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
##     Null deviance: 877.056  on 11  degrees of freedom
## Residual deviance:  20.204  on  5  degrees of freedom
## AIC: 103.14
##
## Number of Fisher Scoring iterations: 4
\end{verbatim}
\begin{alltt}
\hlstd{fitb} \hlkwb{<-} \hlkwd{glm}\hlstd{(}\hlkwd{cbind}\hlstd{(y,nb}\hlopt{-}\hlstd{y)}\hlopt{~}\hlkwd{factor}\hlstd{(sex)}\hlopt{*}\hlkwd{factor}\hlstd{(Dep),}\hlkwc{family}\hlstd{=binomial)}
\hlkwd{anova}\hlstd{(fitb)}
\end{alltt}
\begin{verbatim}
## Analysis of Deviance Table
##
## Model: binomial, link: logit
##
## Response: cbind(y, nb - y)
##
## Terms added sequentially (first to last)
##
##
##                         Df Deviance Resid. Df
## NULL                                       11
## factor(sex)              1    93.45        10
## factor(Dep)              5   763.40         5
## factor(sex):factor(Dep)  5    20.20         0
##                         Resid. Dev
## NULL                        877.06
## factor(sex)                 783.61
## factor(Dep)                  20.20
## factor(sex):factor(Dep)       0.00
\end{verbatim}
\begin{alltt}
\hlkwd{qchisq}\hlstd{(}\hlnum{0.95}\hlstd{,}\hlnum{5}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 11.0705
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{enumerate}
\end{solution}
\begin{solution}{6.6}

\begin{enumerate}
If $Y_{i}\sim Poisson(E_{i}\lambda_{i})$, then, using the canonical link, $$\log(\mu_{i})=log(E_{i})+log(\lambda_{i}),$$ where $\lambda_{i}$ is the mean $SMR$ for observation $i$. $\log(E_{i})$, the natural logarithm of the expected count of lung cancer based on the demographics of the county, is passed to the \texttt{glm} function as an offset factor.

The data for males and females are concatenated to create a model with one covariate, Radon exposure, and one factor predictor, Sex, which takes 2 levels (0 for males and 1 for females).
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Ytot} \hlkwb{<-} \hlkwd{c}\hlstd{(YM,YF)}
\hlstd{Etot} \hlkwb{<-} \hlkwd{c}\hlstd{(EM,EF)}
\hlstd{Sex} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlkwd{rep}\hlstd{(}\hlnum{0}\hlstd{,}\hlkwd{length}\hlstd{(YM)),}\hlkwd{rep}\hlstd{(}\hlnum{1}\hlstd{,}\hlkwd{length}\hlstd{(YF)))} \hlcom{## 1 if female}
\hlstd{Radontot} \hlkwb{<-} \hlkwd{rep}\hlstd{(Radon,}\hlnum{2}\hlstd{)}

\hlstd{modsex} \hlkwb{<-} \hlkwd{glm}\hlstd{(Ytot}\hlopt{~}\hlstd{Sex}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(Etot)),}\hlkwc{family}\hlstd{=poisson)}
\hlstd{modsexrad} \hlkwb{<-} \hlkwd{glm}\hlstd{(Ytot}\hlopt{~}\hlstd{Radontot}\hlopt{+}\hlstd{Sex}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(Etot)),}\hlkwc{family}\hlstd{=poisson)}

\hlkwd{anova}\hlstd{(modsex,modsexrad)}
\end{alltt}
\begin{verbatim}
## Analysis of Deviance Table
##
## Model 1: Ytot ~ Sex + offset(log(Etot))
## Model 2: Ytot ~ Radontot + Sex + offset(log(Etot))
##   Resid. Df Resid. Dev Df Deviance
## 1       172     410.27
## 2       171     364.05  1    46.22
\end{verbatim}
\begin{alltt}
\hlkwd{qchisq}\hlstd{(}\hlnum{0.99}\hlstd{,}\hlnum{1}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 6.634897
\end{verbatim}
\end{kframe}
\end{knitrout}

As shown above, the analysis of deviance shows strong evidence that the radon exposure influences the number of lung cancer in a particular county:
\begin{align*}
\Delta Deviance = 46.22 > \chi^{2}_{(1;0.99)}=6.6349.
\end{align*}

\item The null model and the model including sex only are fitted.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{modtot} \hlkwb{<-} \hlkwd{glm}\hlstd{(Ytot}\hlopt{~}\hlnum{1}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(Etot)),}\hlkwc{family}\hlstd{=poisson)}
\hlstd{modsex} \hlkwb{<-} \hlkwd{glm}\hlstd{(Ytot}\hlopt{~}\hlstd{Sex}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(Etot)),}\hlkwc{family}\hlstd{=poisson)}
\hlkwd{anova}\hlstd{(modtot,modsex)}
\end{alltt}
\begin{verbatim}
## Analysis of Deviance Table
##
## Model 1: Ytot ~ 1 + offset(log(Etot))
## Model 2: Ytot ~ Sex + offset(log(Etot))
##   Resid. Df Resid. Dev Df  Deviance
## 1       173     410.28
## 2       172     410.27  1 0.0093398
\end{verbatim}
\begin{alltt}
\hlkwd{qchisq}\hlstd{(}\hlnum{0.95}\hlstd{,}\hlnum{1}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 3.841459
\end{verbatim}
\end{kframe}
\end{knitrout}
The analysis of deviance shows that $\Delta Deviance= 0.0093398<\chi^{2}_{(1;0.95)}=3.8415$. Hence, the null model is an appropriate simplification of the model including the factor Sex, so the factor is not significant. However, below is the \texttt{R} output for the analysis of deviance when the covariate Radon (known to be significant from a) is included in the model. If we first consider the model with main effects and interactions, we see that $\Delta Deviance= 8.823>\chi^{2}_{(1;0.99)}$, meaning that the model with main effects only is not an adequate simplification of the model with main effects and interactions. Thus, the factor predictor Sex is significant in the model through its interaction with the covariate Radon. Note that even if the main effect of the Sex does not appear to be significant, it is kept in the model by convention.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{modtotrad} \hlkwb{<-} \hlkwd{glm}\hlstd{(Ytot}\hlopt{~}\hlstd{Radontot}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(Etot)),}\hlkwc{family}\hlstd{=poisson)}
\hlstd{modsexrad} \hlkwb{<-} \hlkwd{glm}\hlstd{(Ytot}\hlopt{~}\hlstd{Radontot}\hlopt{+}\hlstd{Sex}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(Etot)),}\hlkwc{family}\hlstd{=poisson)}
\hlstd{modsexradINT} \hlkwb{<-} \hlkwd{glm}\hlstd{(Ytot}\hlopt{~}\hlstd{Radontot}\hlopt{*}\hlstd{Sex}\hlopt{+}\hlkwd{offset}\hlstd{(}\hlkwd{log}\hlstd{(Etot)),}\hlkwc{family}\hlstd{=poisson)}
\hlkwd{anova}\hlstd{(modtot,modtotrad,modsexrad,modsexradINT)}
\end{alltt}
\begin{verbatim}
## Analysis of Deviance Table
##
## Model 1: Ytot ~ 1 + offset(log(Etot))
## Model 2: Ytot ~ Radontot + offset(log(Etot))
## Model 3: Ytot ~ Radontot + Sex + offset(log(Etot))
## Model 4: Ytot ~ Radontot * Sex + offset(log(Etot))
##   Resid. Df Resid. Dev Df Deviance
## 1       173     410.28
## 2       172     364.06  1   46.219
## 3       171     364.05  1    0.011
## 4       170     355.23  1    8.823
\end{verbatim}
\end{kframe}
\end{knitrout}

\item The predictions are obtained using the command
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{predict}\hlstd{(modsexradINT,}\hlkwd{data.frame}\hlstd{(}\hlkwc{Radontot}\hlstd{=}\hlnum{6}\hlstd{,}\hlkwc{Sex}\hlstd{=}\hlnum{0}\hlstd{,}\hlkwc{Etot}\hlstd{=}\hlnum{1}\hlstd{),}\hlkwc{type}\hlstd{=}\hlstr{"response"}\hlstd{,}\hlkwc{se.fit}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
 If the model Sex*Radon is used, we find $$\hat{SMR}_{Sex=0,Radon=6}=0.9708183,$$ with a standard error of 0.01415307.

\item The model Sex*Radon has a deviance of 355.23 on 170 degrees of freedom. A heuristic check for the validity of the model is to calculate the estimated dispersion parameter $$\hat{\phi}=\frac{355.23}{170}=2.089$$ and to compare it with 1, the dispersion parameter implied in the Poisson model. This check suggests the presence of overdispersion in the data as $\hat{\phi}$ is greater than 1. Fitting the quasipoisson model also leads to the same conclusion: the estimated dispersion parameter is 1.98311, closer to 2. Thus, we can conclude that the Poisson model is not adequate, we might consider fitting a Negative Binomial model to capture the overdispersion.
\end{enumerate}
\end{solution}
